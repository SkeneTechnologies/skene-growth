[settings]
# Provider/model used for LLM-as-judge evaluation (future feature)
judge_provider = "anthropic"
judge_model = "claude-sonnet-4-5"
judge_api_key_env = "ANTHROPIC_API_KEY"

# How many times to run each (codebase, model) combo
runs_per_combo = 1

# Default config uses the sample repo fixture for quick testing.
# Add your own codebases below or in a custom config file.

[[codebases]]
name = "skene-dashboard"
path = "/Users/miche/skene/skene-dashboard"

#################
# OpenAI Models #
#################

# 10k TPM Limit
#==============

#[[models]]
#name = "gpt-4"
#provider = "openai"
#model = "gpt-4-0125-preview"
#api_key_env = "OPENAI_API_KEY"

# 30k TPM Limit
#==============

#[[models]]
#name = "gpt-4-turbo"
#provider = "openai"
#model = "gpt-4-turbo-2024-04-09"
#api_key_env = "OPENAI_API_KEY"

#[[models]]
#name = "gpt-4.1"
#provider = "openai"
#model = "gpt-4.1-2025-04-14"
#api_key_env = "OPENAI_API_KEY"

#[[models]]
#name = "gpt-4o"
#provider = "openai"
#model = "gpt-4o-2024-11-20"
#api_key_env = "OPENAI_API_KEY"

#[[models]]
#name = "gpt-5-chat-latest"
#provider = "openai"
#model = "gpt-5-chat-latest"
#api_key_env = "OPENAI_API_KEY"

#[[models]]
#name = "gpt-5-pro"
#provider = "openai"
#model = "gpt-5-pro-2025-10-06"
#api_key_env = "OPENAI_API_KEY"

#[[models]]
#name = "gpt-5.1-chat-latest"
#provider = "openai"
#model = "gpt-5.1-chat-latest"
#api_key_env = "OPENAI_API_KEY"

# 200k TPM Limit
#===============

#[[models]]
#name = "gpt-3.5-turbo"
#provider = "openai"
#model = "gpt-3.5-turbo-0125"
#api_key_env = "OPENAI_API_KEY"

#[[models]]
#name = "gpt-3.5-turbo-16k"
#provider = "openai"
#model = "gpt-3.5-turbo-16k-0613"
#api_key_env = "OPENAI_API_KEY"

#[[models]]
#name = "gpt-4.1-long-context"
#provider = "openai"
#model = "gpt-4.1-long-context"
#api_key_env = "OPENAI_API_KEY"

[[models]]
name = "gpt-4.1-mini"
provider = "openai"
model = "gpt-4.1-mini-2025-04-14"
api_key_env = "OPENAI_API_KEY"

[[models]]
name = "gpt-4.1-nano"
provider = "openai"
model = "gpt-4.1-nano-2025-04-14"
api_key_env = "OPENAI_API_KEY"

[[models]]
name = "gpt-4o-mini"
provider = "openai"
model = "gpt-4o-mini-2024-07-18"
api_key_env = "OPENAI_API_KEY"

#[[models]]
#name = "gpt-5-nano"
#provider = "openai"
#model = "gpt-5-nano-2025-08-07"
#api_key_env = "OPENAI_API_KEY"

#[[models]]
#name = "gpt-5.1-codex-mini"
#provider = "openai"
#model = "gpt-5.1-codex-mini"
#api_key_env = "OPENAI_API_KEY"

# 400k TPM Limit
#===============

#[[models]]
#name = "gpt-4.1-mini-long-context"
#provider = "openai"
#model = "gpt-4.1-mini-long-context"
#api_key_env = "OPENAI_API_KEY"

#[[models]]
#name = "gpt-4.1-nano-long-context"
#provider = "openai"
#model = "gpt-4.1-nano-long-context"
#api_key_env = "OPENAI_API_KEY"

# 500k TPM Limit
#===============

#[[models]]
#name = "gpt-5"
#provider = "openai"
#model = "gpt-5-2025-08-07"
#api_key_env = "OPENAI_API_KEY"

#[[models]]
#name = "gpt-5-codex"
#provider = "openai"
#model = "gpt-5-codex"
#api_key_env = "OPENAI_API_KEY"

[[models]]
name = "gpt-5-mini"
provider = "openai"
model = "gpt-5-mini-2025-08-07"
api_key_env = "OPENAI_API_KEY"

#[[models]]
#name = "gpt-5.1"
#provider = "openai"
#model = "gpt-5.1-2025-11-13"
#api_key_env = "OPENAI_API_KEY"

[[models]]
name = "gpt-5.1-codex"
provider = "openai"
model = "gpt-5.1-codex"
api_key_env = "OPENAI_API_KEY"

#[[models]]
#name = "gpt-5.1-codex-max"
#provider = "openai"
#model = "gpt-5.1-codex-max"
#api_key_env = "OPENAI_API_KEY"

[[models]]
name = "gpt-5.2"
provider = "openai"
model = "gpt-5.2-2025-12-11"
api_key_env = "OPENAI_API_KEY"

#[[models]]
#name = "gpt-5.2-chat-latest"
#provider = "openai"
#model = "gpt-5.2-chat-latest"
#api_key_env = "OPENAI_API_KEY"

#[[models]]
#name = "gpt-5.2-codex"
#provider = "openai"
#model = "gpt-5.2-codex"
#api_key_env = "OPENAI_API_KEY"

[[models]]
name = "gpt-5.2-pro"
provider = "openai"
model = "gpt-5.2-pro-2025-12-11"
api_key_env = "OPENAI_API_KEY"

#################
# Gemini Models #
#################

#[[models]]
#name = "gemini-3-flash-preview"
#provider = "gemini"
#model = "gemini-3-flash-preview"
#api_key_env = "GEMINI_API_KEY"
#
#[[models]]
#name = "gemini-3-pro-preview"
#provider = "gemini"
#model = "gemini-3-pro-preview"
#api_key_env = "GEMINI_API_KEY"
#
#[[models]]
#name = "gemini-2.5-flash"
#provider = "gemini"
#model = "gemini-2.5-flash"
#api_key_env = "GEMINI_API_KEY"
#
#[[models]]
#name = "gemini-2.5-pro"
#provider = "gemini"
#model = "gemini-2.5-pro"
#api_key_env = "GEMINI_API_KEY"

#################
# Claude Models #
#################

#[[models]]
#name = "claude-opus-4-6"
#provider = "anthropic"
#model = "claude-opus-4-6"
#api_key_env = "ANTHROPIC_API_KEY"
#
#[[models]]
#name = "claude-opus-4-5"
#provider = "anthropic"
#model = "claude-opus-4-5"
#api_key_env = "ANTHROPIC_API_KEY"
#
#[[models]]
#name = "claude-sonnet-4-5"
#provider = "anthropic"
#model = "claude-sonnet-4-5"
#api_key_env = "ANTHROPIC_API_KEY"
#
#[[models]]
#name = "claude-haiku-4-5"
#provider = "anthropic"
#model = "claude-haiku-4-5"
#api_key_env = "ANTHROPIC_API_KEY"
